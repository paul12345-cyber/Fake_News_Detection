{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis and preprocessing \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "import re\n",
    "\n",
    "# Model evaluation modules\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "# ML models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### News Data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20800, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Jackie Mason: Hollywood Would Love Trump if He...</td>\n",
       "      <td>Daniel Nussbaum</td>\n",
       "      <td>In these trying times, Jackie Mason is the Voi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Life: Life Of Luxury: Elton John’s 6 Favorite ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ever wonder how Britain’s most iconic pop pian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Benoît Hamon Wins French Socialist Party’s Pre...</td>\n",
       "      <td>Alissa J. Rubin</td>\n",
       "      <td>PARIS  —   France chose an idealistic, traditi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "5   5  Jackie Mason: Hollywood Would Love Trump if He...     Daniel Nussbaum   \n",
       "6   6  Life: Life Of Luxury: Elton John’s 6 Favorite ...                 NaN   \n",
       "7   7  Benoît Hamon Wins French Socialist Party’s Pre...     Alissa J. Rubin   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  \n",
       "5  In these trying times, Jackie Mason is the Voi...      0  \n",
       "6  Ever wonder how Britain’s most iconic pop pian...      1  \n",
       "7  PARIS  —   France chose an idealistic, traditi...      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news=pd.read_csv('train.csv')\n",
    "print(news.shape)\n",
    "news.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most active Authors with more than 100 news articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pam Key                243\n",
       "admin                  193\n",
       "Jerome Hudson          166\n",
       "Charlie Spiering       141\n",
       "John Hayward           140\n",
       "Katherine Rodriguez    124\n",
       "Warner Todd Huston     122\n",
       "Ian Hanchett           119\n",
       "Breitbart News         118\n",
       "Daniel Nussbaum        112\n",
       "Jeff Poor              107\n",
       "AWR Hawkins            107\n",
       "Joel B. Pollak         106\n",
       "Trent Baker            102\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auth=news['author'].value_counts()\n",
    "auth=auth[auth>100]\n",
    "auth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most active authors with coresponding number of fake/authentic news articles \n",
    "#### (0-fake, 1-authentic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author               label\n",
       "AWR Hawkins          0        107\n",
       "Breitbart News       0        118\n",
       "Charlie Spiering     0        141\n",
       "Daniel Nussbaum      0        112\n",
       "Ian Hanchett         0        119\n",
       "Jeff Poor            0        107\n",
       "Jerome Hudson        0        166\n",
       "Joel B. Pollak       0        106\n",
       "John Hayward         0        140\n",
       "Katherine Rodriguez  0        124\n",
       "Pam Key              0        242\n",
       "                     1          1\n",
       "Trent Baker          0        102\n",
       "Warner Todd Huston   0        122\n",
       "admin                1        193\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auth_count=news.groupby(['author','label'])['label'].count()\n",
    "\n",
    "auth=list(auth.index)    # get list of top active authors with over 100 news articles\n",
    "auth_count[auth]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the above output, except  author 'Admin', all other most active authors post 'fake news'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove missing values and reset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18285, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news=news.dropna()\n",
    "news.reset_index(inplace=True)\n",
    "news.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing: Stemming, removing stopwords and non-alphanumeric characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=PorterStemmer()\n",
    "tit=[]\n",
    "for n in range(0,len(news)):\n",
    "    msg=re.sub('[^a-zA-Z0-9]',' ',news['title'][n])\n",
    "    msg=msg.lower()\n",
    "    msg=word_tokenize(msg)          # split text message into a list\n",
    "    msg=[ps.stem(w) for w in msg if not w in stopwords.words('english')]\n",
    "    msg = ' '.join(msg)    # Join list back into sentence\n",
    "    tit.append(msg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hous dem aid even see comey letter jason chaffetz tweet',\n",
       " 'flynn hillari clinton big woman campu breitbart',\n",
       " 'truth might get fire',\n",
       " '15 civilian kill singl us airstrik identifi',\n",
       " 'iranian woman jail fiction unpublish stori woman stone death adulteri']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tit[0:5]  # First 5 titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split news dataset into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into 80% for training and 20% testing \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "Y=news.iloc[:,-1]\n",
    "x_train, x_test, y_train, y_test = train_test_split(tit,Y, test_size=0.2, random_state=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of x_train: 14628 and y_train:14628 \n"
     ]
    }
   ],
   "source": [
    "print('length of x_train: %d and y_train:%d ' %(len(x_train),len(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline([('vect', CountVectorizer(max_features=5000)),\n",
    "                   ('tfidf', TfidfTransformer()),\n",
    "                ('classifier', LogisticRegression(random_state=42))])\n",
    "\n",
    "pipe_rf = Pipeline([('vect', CountVectorizer(max_features=5000)),\n",
    "                   ('tfidf', TfidfTransformer()),\n",
    "            ('classifier', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "pipe_svm = Pipeline([('vect', CountVectorizer(max_features=5000)),\n",
    "                   ('tfidf', TfidfTransformer()),\n",
    "            ('classifier', svm.SVC(random_state=42))]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_range = [9, 10]\n",
    "param_range_fl = [1.0, 0.5]\n",
    "\n",
    "grid_params_lr = [{'classifier__penalty': ['l1', 'l2'],\n",
    "        'classifier__C': param_range_fl,\n",
    "        'classifier__solver': ['liblinear']}] \n",
    "\n",
    "\n",
    "grid_params_rf = [{'classifier__criterion': ['gini', 'entropy'],\n",
    "        'classifier__max_depth': param_range,\n",
    "        'classifier__min_samples_split': param_range[1:]}]\n",
    "\n",
    "grid_params_svm = [{'classifier__kernel': ['linear', 'rbf'], \n",
    "        'classifier__C': param_range}]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = -1\n",
    "\n",
    "LR = GridSearchCV(estimator=pipe_lr,\n",
    "            param_grid=grid_params_lr,\n",
    "            scoring='accuracy',\n",
    "            cv=10) \n",
    "\n",
    "\n",
    "\n",
    "RF = GridSearchCV(estimator=pipe_rf,\n",
    "            param_grid=grid_params_rf,\n",
    "            scoring='accuracy',\n",
    "            cv=10, \n",
    "            n_jobs=jobs)\n",
    "\n",
    "\n",
    "SVM = GridSearchCV(estimator=pipe_svm,\n",
    "            param_grid=grid_params_svm,\n",
    "            scoring='accuracy',\n",
    "            cv=10,\n",
    "            n_jobs=jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding best classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and parameter optimizations...\n",
      "\n",
      "Estimator: Support Vector Machine\n",
      "Best params are : {'classifier__C': 9, 'classifier__kernel': 'rbf'}\n",
      "Best training accuracy: 0.934\n",
      "Test set accuracy score for best params: 0.933 \n",
      "\n",
      "Estimator: Random Forest\n",
      "Best params are : {'classifier__criterion': 'gini', 'classifier__max_depth': 10, 'classifier__min_samples_split': 10}\n",
      "Best training accuracy: 0.888\n",
      "Test set accuracy score for best params: 0.897 \n",
      "\n",
      "Estimator: Logistic Regression\n",
      "Best params are : {'classifier__C': 1.0, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "Best training accuracy: 0.923\n",
      "Test set accuracy score for best params: 0.924 \n",
      "\n",
      "Classifier with best test set accuracy: Support Vector Machine\n"
     ]
    }
   ],
   "source": [
    "\n",
    "grd = [SVM,RF,LR]\n",
    "\n",
    "grd_dict = {0: 'Support Vector Machine', \n",
    "        1: 'Random Forest',\n",
    "        2: 'Logistic Regression'}\n",
    "\n",
    "# Fit the grid search objects\n",
    "print('Model and parameter optimizations...')\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_gs = ''\n",
    "for idx, gs in enumerate(grd):\n",
    "    print('\\nEstimator: %s' % grd_dict[idx])\n",
    "    gs.fit(x_train, y_train)\n",
    "    print('Best params are : %s' % gs.best_params_)\n",
    "    # Best training data accuracy\n",
    "    print('Best training accuracy: %.3f' % gs.best_score_)\n",
    "    # Predict on test data with best params\n",
    "    y_pred = gs.predict(x_test)\n",
    "    # Test data accuracy of model with best params\n",
    "    print('Test set accuracy score for best params: %.3f ' % accuracy_score(y_test, y_pred))\n",
    "    # Track best (highest test accuracy) model\n",
    "    if accuracy_score(y_test, y_pred) > best_acc:\n",
    "        best_acc = accuracy_score(y_test, y_pred)\n",
    "        best_gs = gs\n",
    "        best_clf = idx\n",
    "print('\\nClassifier with best test set accuracy: %s' % grd_dict[best_clf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
